@inproceedings{henning-etal-2022-mist,
    title = "MiST: a Large-Scale Annotated Resource and Neural Models for Functions of Modal Verbs in English Scientific Text",
    author = {Henning, Sophie  and
      Macher, Nicole  and
      Gr{\"u}newald, Stefan  and
      Friedrich, Annemarie},
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    abbr = "Findings",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    abstract = "Modal verbs (e.g., can, should or must) occur highly frequently in scientific articles. Decoding their function is not straightforward: they are often used for hedging, but they may also denote abilities and restrictions. Understanding their meaning is important for accurate information extraction from scientific text. To foster research on the usage of modals in this genre, we introduce the MIST (Modals In Scientific Text) dataset, which contains 3737 modal instances in five scientific domains annotated for their semantic, pragmatic, or rhetorical function. We systematically evaluate a set of competitive neural architectures on MIST. Transfer experiments reveal that leveraging non-scientific data is of limited benefit for modeling the distinctions in MIST. Our corpus analysis provides evidence that scientific communities differ in their usage of modal verbs, yet, classifiers trained on scientific data generalize to some extent to unseen scientific domains.",
    pdf = "emnlp2022_mist.pdf"
}

@inproceedings{burkle-etal-2021-corpus,
    title = "A Corpus Study of Creating Rule-Based Enhanced {U}niversal {D}ependencies for {G}erman",
    author = {B{\"u}rkle, Teresa  and
      Gr{\"u}newald, Stefan  and
      Friedrich, Annemarie},
    booktitle = "Proceedings of The Joint 15th Linguistic Annotation Workshop (LAW) and 3rd Designing Meaning Representations (DMR) Workshop",
    abbr = "LAW",
    month = nov # " 11",
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.law-1.9",
    pages = "85--95",
    abstract = "In this paper, we present a first attempt at enriching German Universal Dependencies (UD) treebanks with enhanced dependencies. Similarly to the converter for English (Schuster and Manning, 2016), we develop a rule-based system for deriving enhanced dependencies from the basic layer, covering three linguistic phenomena: relative clauses, coordination, and raising/control. For quality control, we manually correct or validate a set of 196 sentences, finding that around 90{\%} of added relations are correct. Our data analysis reveals that difficulties arise mainly due to inconsistencies in the basic layer annotations. We show that the English system is in general applicable to German data, but that adapting to the particularities of the German treebanks and language increases precision and recall by up to 10{\%}. Comparing the application of our converter on gold standard dependencies vs. automatic parses, we find that F1 drops by around 10{\%} in the latter setting due to error propagation. Finally, an enhanced UD parser trained on a converted treebank performs poorly when evaluated against our annotations, indicating that more work remains to be done to create gold standard enhanced German treebanks.",
    pdf = "law2021_german_ud.pdf"
}

@inproceedings{sineva-etal-2021-negation,
    title = "Negation-Instance Based Evaluation of End-to-End Negation Resolution",
    author = {Sineva, Elizaveta  and
      Gr{\"u}newald, Stefan  and
      Friedrich, Annemarie  and
      Kuhn, Jonas},
    booktitle = "Proceedings of the 25th Conference on Computational Natural Language Learning",
    abbr = "CoNLL",
    month = nov,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.conll-1.41",
    pages = "528--543",
    abstract = "In this paper, we revisit the task of negation resolution, which includes the subtasks of cue detection (e.g. {``}not{''}, {``}never{''}) and scope resolution. In the context of previous shared tasks, a variety of evaluation metrics have been proposed. Subsequent works usually use different subsets of these, including variations and custom implementations, rendering meaningful comparisons between systems difficult. Examining the problem both from a linguistic perspective and from a downstream viewpoint, we here argue for a negation-instance based approach to evaluating negation resolution. Our proposed metrics correspond to expectations over per-instance scores and hence are intuitively interpretable. To render research comparable and to foster future work, we provide results for a set of current state-of-the-art systems for negation resolution on three English corpora, and make our implementation of the evaluation scripts publicly available.",
    pdf = "conll2021_negation.pdf"
}

@inproceedings{grunewald-etal-2021-robertnlp,
    title = "{R}obert{NLP} at the {IWPT} 2021 Shared Task: Simple Enhanced {UD} Parsing for 17 Languages",
    author = {Gr{\"u}newald, Stefan  and
      Oertel, Frederik Tobias  and
      Friedrich, Annemarie},
    booktitle = "Proceedings of the 17th International Conference on Parsing Technologies and the IWPT 2021 Shared Task on Parsing into Enhanced Universal Dependencies (IWPT 2021)",
    abbr = "IWPT",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.iwpt-1.21",
    doi = "10.18653/v1/2021.iwpt-1.21",
    pages = "196--203",
    abstract = "This paper presents our multilingual dependency parsing system as used in the IWPT 2021 Shared Task on Parsing into Enhanced Universal Dependencies. Our system consists of an unfactorized biaffine classifier that operates directly on fine-tuned XLM-R embeddings and generates enhanced UD graphs by predicting the best dependency label (or absence of a dependency) for each pair of tokens. To avoid sparsity issues resulting from lexicalized dependency labels, we replace lexical items in relations with placeholders at training and prediction time, later retrieving them from the parse via a hybrid rule-based/machine-learning system. In addition, we utilize model ensembling at prediction time. Our system achieves high parsing accuracy on the blind test data, ranking 3rd out of 9 with an average ELAS F1 score of 86.97.",
    pdf = "iwpt2021_sharedtask.pdf",
}

@inproceedings{grunewald-etal-2021-applying,
    title = "Applying Occam{'}s Razor to Transformer-Based Dependency Parsing: What Works, What Doesn{'}t, and What is Really Necessary",
    author = {Gr{\"u}newald, Stefan  and
      Friedrich, Annemarie  and
      Kuhn, Jonas},
    booktitle = "Proceedings of the 17th International Conference on Parsing Technologies and the IWPT 2021 Shared Task on Parsing into Enhanced Universal Dependencies (IWPT 2021)",
    abbr = "IWPT",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.iwpt-1.13",
    doi = "10.18653/v1/2021.iwpt-1.13",
    pages = "131--144",
    abstract = "The introduction of pre-trained transformer-based contextualized word embeddings has led to considerable improvements in the accuracy of graph-based parsers for frameworks such as Universal Dependencies (UD). However, previous works differ in various dimensions, including their choice of pre-trained language models and whether they use LSTM layers. With the aims of disentangling the effects of these choices and identifying a simple yet widely applicable architecture, we introduce STEPS, a new modular graph-based dependency parser. Using STEPS, we perform a series of analyses on the UD corpora of a diverse set of languages. We find that the choice of pre-trained embeddings has by far the greatest impact on parser performance and identify XLM-R as a robust choice across the languages in our study. Adding LSTM layers provides no benefits when using transformer-based embeddings. A multi-task training setup outputting additional UD features may contort results. Taking these insights together, we propose a simple but widely applicable parser architecture and configuration, achieving new state-of-the-art results (in terms of LAS) for 10 out of 12 diverse languages.",
    pdf = "iwpt2021_occam.pdf",
}

@misc{grunewald-2021-mst,
    title = "Maximum Spanning Trees Are Invariant to Temperature Scaling in Graph-based Dependency Parsing", 
    author = {Grünewald, Stefan},
    year = "2021",
    month = jun,
    abbr = "arXiv",
    eprint = {2106.08159},
    url = "https://arxiv.org/abs/2106.08159",
    abstract = "Modern graph-based syntactic dependency parsers operate by predicting, for each token within a sentence, a probability distribution over its possible syntactic heads (i.e., all other tokens) and then extracting a maximum spanning tree from the resulting log-probabilities. Nowadays, virtually all such parsers utilize deep neural networks and may thus be susceptible to miscalibration (in particular, overconfident predictions). In this paper, we prove that temperature scaling, a popular technique for post-hoc calibration of neural networks, cannot change the output of the aforementioned procedure. We conclude that other techniques are needed to tackle miscalibration in graph-based dependency parsers in a way that improves parsing accuracy. ",
    pdf = "mst_temp_proof.pdf",
}

@inproceedings{grunewald-etal-2021-coordinate,
    title = "Coordinate Constructions in {E}nglish Enhanced {U}niversal {D}ependencies: Analysis and Computational Modeling",
    author = {Grünewald, Stefan and Piccirilli, Prisca and Friedrich, Annemarie},
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2021.eacl-main.67",
    pages = "795--809",
    abbr = "EACL",
    abstract = "In this paper, we address the representation of coordinate constructions in Enhanced Universal Dependencies (UD), where relevant dependency links are propagated from conjunction heads to other conjuncts. English treebanks for enhanced UD have been created from gold basic dependencies using a heuristic rule-based converter, which propagates only core arguments. With the aim of determining which set of links should be propagated from a semantic perspective, we create a large-scale dataset of manually edited syntax graphs. We identify several systematic errors in the original data, and propose to also propagate adjuncts. We observe high inter-annotator agreement for this semantic annotation task. Using our new manually verified dataset, we perform the first principled comparison of rule-based and (partially novel) machine-learning based methods for conjunction propagation for English. We show that learning propagation rules is more effective than hand-designing heuristic rules. When using automatic parses, our neural graph-parser based edge predictor outperforms the currently predominant pipelines using a basic-layer tree parser plus converters.",
    pdf = "coord_paper.pdf",
    slides = "coord_slides.pdf",
    poster = "coord_poster.pdf"
}

@inproceedings{grunewald-friedrich-2020-unifying,
    title = "Unifying the Treatment of Preposition-Determiner Contractions in {G}erman {U}niversal {D}ependencies Treebanks",
    author = {Grünewald, Stefan and Friedrich, Annemarie},
    booktitle = "Proceedings of the Fourth Workshop on Universal Dependencies (UDW 2020)",
    abbr = "UDW",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.udw-1.11",
    pages = "94--98",
    abstract = "HDT-UD, the largest German UD treebank by a large margin, as well as the German-LIT treebank, currently do not analyze preposition-determiner contractions such as zum (= zu dem, {``}to the{``}) as multi-word tokens, which is inconsistent both with UD guidelines as well as other German UD corpora (GSD and PUD). In this paper, we show that harmonizing corpora with regard to this highly frequent phenomenon using a lookup-table based approach leads to a considerable increase in automatic parsing performance.",
    pdf = "contractions_paper.pdf",
    poster = "contractions_poster.pdf"
}

@inproceedings{grunewald-friedrich-2020-robertnlp,
    title = "{R}obert{NLP} at the {IWPT} 2020 Shared Task: Surprisingly Simple Enhanced {UD} Parsing for {E}nglish",
    author = {Grünewald, Stefan and Friedrich, Annemarie},
    booktitle = "Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies",
    abbr = "IWPT",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.iwpt-1.26",
    doi = "10.18653/v1/2020.iwpt-1.26",
    pages = "245--252",
    abstract = "This paper presents our system at the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies. Using a biaffine classifier architecture (Dozat and Manning, 2017) which operates directly on finetuned RoBERTa embeddings, our parser generates enhanced UD graphs by predicting the best dependency label (or absence of a dependency) for each pair of tokens in the sentence. We address label sparsity issues by replacing lexical items in relations with placeholders at prediction time, later retrieving them from the parse in a rule-based fashion. In addition, we ensure structural graph constraints using a simple set of heuristics. On the English blind test data, our system achieves a very high parsing accuracy, ranking 1st out of 10 with an ELAS F1 score of 88.94{\%}.",
    pdf = "robertnlp_paper.pdf",
    slides = "robertnlp_slides.pdf"
}

@inproceedings{grunewald-etal-2018-generalized,
    title = "Generalized Chart Constraints for Efficient {PCFG} and {TAG} Parsing",
    author = {Grünewald, Stefan and
      Henning, Sophie  and
      Koller, Alexander},
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    abbr = "ACL",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-2099",
    doi = "10.18653/v1/P18-2099",
    pages = "626--631",
    abstract = "Chart constraints, which specify at which string positions a constituent may begin or end, have been shown to speed up chart parsers for PCFGs. We generalize chart constraints to more expressive grammar formalisms and describe a neural tagger which predicts chart constraints at very high precision. Our constraints accelerate both PCFG and TAG parsing, and combine effectively with other pruning techniques (coarse-to-fine and supertagging) for an overall speedup of two orders of magnitude, while improving accuracy.",
    pdf = "cc_paper.pdf",
    poster = "cc_poster.pdf"
}
